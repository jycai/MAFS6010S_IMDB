{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 1: Text vectorization with support vector classification(SVC) and Multinomial Naive Bayes classfication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "import re,string,unicodedata\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.stem import LancasterStemmer,WordNetLemmatizer\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the dataset\n",
    "dataset = pd.read_csv(\"IMDB Dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: data pre-processing\n",
    "\n",
    "### The text_clean() function provides basic data cleaning for NLP:\n",
    "a) remove HTML contents like \"< br>\"   \n",
    "b) remove punctutions and special characters like '\\'  \n",
    "c) remove stopwords like \"is\", \"the\", which do not offer much insight  \n",
    "d) lemmatize the words to bring back multiple forms of same word like 'coming', 'comes' into 'come'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_clean(review):\n",
    "    soup = BeautifulSoup(review, \"html.parser\")\n",
    "    review = soup.get_text() \n",
    "    review = re.sub('\\[[^]]*\\]', ' ', review)\n",
    "    review = re.sub('[^a-zA-Z]', ' ', review)\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [word for word in review if not word in set(stopwords.words('english'))]\n",
    "    lem = WordNetLemmatizer()\n",
    "    review = [lem.lemmatize(word) for word in review]\n",
    "    review = ' '.join(review)\n",
    "    \n",
    "    return review\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below is an example before and after data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams\\' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master\\'s of comedy and his life. <br /><br />The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional \\'dream\\' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell\\'s murals decorating every surface) are terribly well done.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Original text\n",
    "review = dataset['review'].loc[1]\n",
    "corpus = []\n",
    "corpus.append(review)\n",
    "corpus\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wonderful little production filming technique unassuming old time bbc fashion give comforting sometimes discomforting sense realism entire piece actor extremely well chosen michael sheen got polari voice pat truly see seamless editing guided reference williams diary entry well worth watching terrificly written performed piece masterful production one great master comedy life realism really come home little thing fantasy guard rather use traditional dream technique remains solid disappears play knowledge sens particularly scene concerning orton halliwell set particularly flat halliwell mural decorating every surface terribly well done']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cleaned text\n",
    "corpus[0] = text_clean(corpus[0])\n",
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Vectorization: encode the text to numericals\n",
    "## We apply three methods to vectorize the text: \n",
    "### a) count vectorization  \n",
    "### b) binary count vectorization  \n",
    "### c) text frequency - inverse document frequency (tfidf) vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1,\n",
       "        1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a) count vectorization: each word is encoded by the number of times it appeared in the text\n",
    "count_vec = CountVectorizer()\n",
    "review_count_vec = count_vec.fit_transform(corpus)\n",
    "review_count_vec.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# b) binary count vectorization: similar to a), but all it only check whether a word appears, thus only 1 for all words\n",
    "count_vec_bin = CountVectorizer(binary=True)\n",
    "review_count_vec_bin = count_vec_bin.fit_transform(corpus)\n",
    "review_count_vec_bin.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.09712859, 0.09712859, 0.09712859, 0.09712859, 0.09712859,\n",
       "        0.09712859, 0.09712859, 0.09712859, 0.09712859, 0.09712859,\n",
       "        0.09712859, 0.09712859, 0.09712859, 0.09712859, 0.09712859,\n",
       "        0.09712859, 0.09712859, 0.09712859, 0.09712859, 0.09712859,\n",
       "        0.09712859, 0.09712859, 0.09712859, 0.09712859, 0.09712859,\n",
       "        0.09712859, 0.09712859, 0.19425717, 0.09712859, 0.09712859,\n",
       "        0.09712859, 0.19425717, 0.09712859, 0.09712859, 0.09712859,\n",
       "        0.09712859, 0.09712859, 0.09712859, 0.09712859, 0.19425717,\n",
       "        0.09712859, 0.09712859, 0.19425717, 0.09712859, 0.09712859,\n",
       "        0.19425717, 0.09712859, 0.19425717, 0.09712859, 0.09712859,\n",
       "        0.09712859, 0.09712859, 0.09712859, 0.09712859, 0.09712859,\n",
       "        0.09712859, 0.09712859, 0.09712859, 0.09712859, 0.09712859,\n",
       "        0.09712859, 0.19425717, 0.09712859, 0.09712859, 0.09712859,\n",
       "        0.09712859, 0.09712859, 0.09712859, 0.09712859, 0.09712859,\n",
       "        0.09712859, 0.09712859, 0.29138576, 0.09712859, 0.09712859,\n",
       "        0.09712859, 0.09712859]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# c) TF : how many times a word (term) appears in a text (document). \n",
    "#    IDF: log(# of documents in corpus/# of documents containing the term).\n",
    "#    TF-IDF: TF * IDF.\n",
    "tfidf_vec = TfidfVectorizer()\n",
    "review_tfidf_vec = tfidf_vec.fit_transform(corpus)\n",
    "review_tfidf_vec.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: split the whole dataset into 75% training and 25% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train, dataset_test, train_data_label, test_data_label = train_test_split(dataset['review'], dataset['sentiment'], test_size=0.25, random_state=42)\n",
    "\n",
    "train_data_label = (train_data_label.replace({'positive': 1, 'negative': 0})).values\n",
    "test_data_label  = (test_data_label.replace({'positive': 1, 'negative': 0})).values\n",
    "\n",
    "corpus_train = []\n",
    "corpus_test  = []\n",
    "\n",
    "for i in range(dataset_train.shape[0]):\n",
    "    corpus_train.append(text_clean(dataset_train.iloc[i]))\n",
    "    \n",
    "for j in range(dataset_test.shape[0]):\n",
    "    corpus_test.append(text_clean(dataset_test.iloc[j]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: fit data with Support Vector Classification\n",
    "\n",
    "### a) using TFIDF vectorization, fit with SVC: the accuracy is 90.29%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vec = TfidfVectorizer(ngram_range=(1, 3))\n",
    "\n",
    "tfidf_vec_train = tfidf_vec.fit_transform(corpus_train)\n",
    "tfidf_vec_test = tfidf_vec.transform(corpus_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_svc = LinearSVC(C=0.5, random_state=42)\n",
    "linear_svc.fit(tfidf_vec_train, train_data_label)\n",
    "\n",
    "predict = linear_svc.predict(tfidf_vec_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.91      0.89      0.90      6157\n",
      "    Positive       0.89      0.92      0.91      6343\n",
      "\n",
      "    accuracy                           0.90     12500\n",
      "   macro avg       0.90      0.90      0.90     12500\n",
      "weighted avg       0.90      0.90      0.90     12500\n",
      "\n",
      "Confusion Matrix: \n",
      " [[5467  690]\n",
      " [ 524 5819]]\n",
      "Accuracy: \n",
      " 0.90288\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report: \\n\", classification_report(test_data_label, predict,target_names=['Negative','Positive']))\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(test_data_label, predict))\n",
    "print(\"Accuracy: \\n\", accuracy_score(test_data_label, predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) using count vectorization, fit with SVC: the accuracy is 89.77%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vec = CountVectorizer(ngram_range=(1, 3), binary=False)\n",
    "count_vec_train = count_vec.fit_transform(corpus_train)\n",
    "count_vec_test = count_vec.transform(corpus_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_svc_count = LinearSVC(C=0.5, random_state=42, max_iter=5000)\n",
    "linear_svc_count.fit(count_vec_train, train_data_label)\n",
    "\n",
    "predict_count = linear_svc_count.predict(count_vec_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.90      0.89      0.90      6157\n",
      "    Positive       0.90      0.90      0.90      6343\n",
      "\n",
      "    accuracy                           0.90     12500\n",
      "   macro avg       0.90      0.90      0.90     12500\n",
      "weighted avg       0.90      0.90      0.90     12500\n",
      "\n",
      "Confusion Matrix: \n",
      " [[5489  668]\n",
      " [ 611 5732]]\n",
      "Accuracy: \n",
      " 0.89768\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report: \\n\", classification_report(test_data_label, predict_count,target_names=['Negative','Positive']))\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(test_data_label, predict_count))\n",
    "print(\"Accuracy: \\n\", accuracy_score(test_data_label, predict_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) using binary count vectorization, fit with SVC: the accuracy is 89.46%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_vec = CountVectorizer(ngram_range=(1, 3), binary=True)\n",
    "ind_vec_train = ind_vec.fit_transform(corpus_train)\n",
    "ind_vec_test = ind_vec.transform(corpus_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_svc_ind = LinearSVC(C=0.5, random_state=42)\n",
    "linear_svc_ind.fit(ind_vec_train, train_data_label)\n",
    "\n",
    "predict_ind = linear_svc_ind.predict(ind_vec_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.90      0.89      0.89      6157\n",
      "    Positive       0.89      0.90      0.90      6343\n",
      "\n",
      "    accuracy                           0.89     12500\n",
      "   macro avg       0.89      0.89      0.89     12500\n",
      "weighted avg       0.89      0.89      0.89     12500\n",
      "\n",
      "Confusion Matrix: \n",
      " [[5461  696]\n",
      " [ 621 5722]]\n",
      "Accuracy: \n",
      " 0.89464\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report: \\n\", classification_report(test_data_label, predict_ind,target_names=['Negative','Positive']))\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(test_data_label, predict_ind))\n",
    "print(\"Accuracy: \\n\", accuracy_score(test_data_label, predict_ind))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step5: fit the data to Multinomial Naive Bayes classifier. \n",
    "## Bayesian model uses prior probabilities to predict posterior probabilites which is helpful for classification with discrete features like text classification\n",
    "\n",
    "### a) using TFIDF vectorization, fit with SVC: the accuracy is 86.6%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vec_NB = TfidfVectorizer(ngram_range=(1, 1))\n",
    "tfidf_vec_train_NB = tfidf_vec_NB.fit_transform(corpus_train)\n",
    "\n",
    "tfidf_vec_test_NB = tfidf_vec_NB.transform(corpus_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "ch2 = SelectKBest(chi2, k=50000)\n",
    "tfidf_vec_train_NB = ch2.fit_transform(tfidf_vec_train_NB, train_data_label)\n",
    "tfidf_vec_test_NB  = ch2.transform(tfidf_vec_test_NB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = tfidf_vec_NB.get_feature_names()\n",
    "feature_names = [feature_names[i] for i\n",
    "                         in ch2.get_support(indices=True)]\n",
    "feature_names = np.asarray(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "multi_clf = MultinomialNB()\n",
    "multi_clf.fit(tfidf_vec_train_NB, train_data_label)\n",
    "\n",
    "predict_NB = multi_clf.predict(tfidf_vec_test_NB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.85      0.88      0.87      6157\n",
      "    Positive       0.88      0.85      0.87      6343\n",
      "\n",
      "    accuracy                           0.87     12500\n",
      "   macro avg       0.87      0.87      0.87     12500\n",
      "weighted avg       0.87      0.87      0.87     12500\n",
      "\n",
      "Confusion Matrix: \n",
      " [[5424  733]\n",
      " [ 938 5405]]\n",
      "Accuracy: \n",
      " 0.86632\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report: \\n\", classification_report(test_data_label, predict_NB,target_names=['Negative','Positive']))\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(test_data_label, predict_NB))\n",
    "print(\"Accuracy: \\n\", accuracy_score(test_data_label, predict_NB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) using count vectorization, fit with SVC: the accuracy is 88.7%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vec_NB = CountVectorizer(ngram_range=(1, 3), binary=False)\n",
    "count_vec_train_NB = count_vec_NB.fit_transform(corpus_train)\n",
    "count_vec_test_NB = count_vec_NB.transform(corpus_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_clf_count = MultinomialNB()\n",
    "multi_clf_count.fit(count_vec_train_NB, train_data_label)\n",
    "\n",
    "predict_NB_count = multi_clf_count.predict(count_vec_test_NB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.88      0.89      0.89      6157\n",
      "    Positive       0.90      0.88      0.89      6343\n",
      "\n",
      "    accuracy                           0.89     12500\n",
      "   macro avg       0.89      0.89      0.89     12500\n",
      "weighted avg       0.89      0.89      0.89     12500\n",
      "\n",
      "Confusion Matrix: \n",
      " [[5503  654]\n",
      " [ 752 5591]]\n",
      "Accuracy: \n",
      " 0.88752\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report: \\n\", classification_report(test_data_label, predict_NB_count,target_names=['Negative','Positive']))\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(test_data_label, predict_NB_count))\n",
    "print(\"Accuracy: \\n\", accuracy_score(test_data_label, predict_NB_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best model: SVC + TFIDF vectorization\n",
    "## Let's see some prediction results from the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I really liked this Summerslam due to the look...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not many television shows appeal to quite as m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The film quickly gets to a major chase scene w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jane Austen would definitely approve of this o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Expectations were somewhat high for me when I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I've watched this movie on a fairly regular ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>For once a story of hope highlighted over the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Okay, I didn't get the Purgatory thing the fir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I was very disappointed with this series. It h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The first 30 minutes of Tinseltown had my fing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review\n",
       "0  I really liked this Summerslam due to the look...\n",
       "1  Not many television shows appeal to quite as m...\n",
       "2  The film quickly gets to a major chase scene w...\n",
       "3  Jane Austen would definitely approve of this o...\n",
       "4  Expectations were somewhat high for me when I ...\n",
       "5  I've watched this movie on a fairly regular ba...\n",
       "6  For once a story of hope highlighted over the ...\n",
       "7  Okay, I didn't get the Purgatory thing the fir...\n",
       "8  I was very disappointed with this series. It h...\n",
       "9  The first 30 minutes of Tinseltown had my fing..."
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_predict = dataset_test.copy()\n",
    "dataset_predict = pd.DataFrame(dataset_predict)\n",
    "dataset_predict.columns = ['review']\n",
    "dataset_predict = dataset_predict.reset_index()\n",
    "dataset_predict = dataset_predict.drop(['index'], axis=1)\n",
    "dataset_predict.iloc[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_actual_label = test_data_label.copy()\n",
    "test_actual_label = pd.DataFrame(test_actual_label)\n",
    "test_actual_label.columns = ['sentiment']\n",
    "test_actual_label['sentiment'] = test_actual_label['sentiment'].replace({1: 'positive', 0: 'negative'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predicted_label = predict.copy()\n",
    "test_predicted_label = pd.DataFrame(test_predicted_label)\n",
    "test_predicted_label.columns = ['predicted_sentiment']\n",
    "test_predicted_label['predicted_sentiment'] = test_predicted_label['predicted_sentiment'].replace({1: 'positive', 0: 'negative'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>predicted_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I really liked this Summerslam due to the look...</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not many television shows appeal to quite as m...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The film quickly gets to a major chase scene w...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jane Austen would definitely approve of this o...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Expectations were somewhat high for me when I ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I've watched this movie on a fairly regular ba...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>For once a story of hope highlighted over the ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Okay, I didn't get the Purgatory thing the fir...</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I was very disappointed with this series. It h...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The first 30 minutes of Tinseltown had my fing...</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  \\\n",
       "0  I really liked this Summerslam due to the look...  positive   \n",
       "1  Not many television shows appeal to quite as m...  positive   \n",
       "2  The film quickly gets to a major chase scene w...  negative   \n",
       "3  Jane Austen would definitely approve of this o...  positive   \n",
       "4  Expectations were somewhat high for me when I ...  negative   \n",
       "5  I've watched this movie on a fairly regular ba...  positive   \n",
       "6  For once a story of hope highlighted over the ...  positive   \n",
       "7  Okay, I didn't get the Purgatory thing the fir...  positive   \n",
       "8  I was very disappointed with this series. It h...  negative   \n",
       "9  The first 30 minutes of Tinseltown had my fing...  negative   \n",
       "\n",
       "  predicted_sentiment  \n",
       "0            negative  \n",
       "1            positive  \n",
       "2            negative  \n",
       "3            positive  \n",
       "4            negative  \n",
       "5            positive  \n",
       "6            positive  \n",
       "7            negative  \n",
       "8            negative  \n",
       "9            negative  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result = pd.concat([dataset_predict, test_actual_label, test_predicted_label], axis=1)\n",
    "test_result.iloc[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
